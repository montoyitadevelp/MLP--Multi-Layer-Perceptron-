# ğŸ§  MLP Credit Scoring - Multi-Layer Perceptron

> Sistema de evaluaciÃ³n de riesgo crediticio basado en redes neuronales profundas (Deep Learning) utilizando PyTorch.

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-orange.svg)](https://mlflow.org/)

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#-descripciÃ³n)
- [Arquitectura del Proyecto](#-arquitectura-del-proyecto)
- [Dataset](#-dataset)
- [Modelo de Red Neuronal](#-modelo-de-red-neuronal)
- [Proceso de Entrenamiento](#-proceso-de-entrenamiento)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [ConfiguraciÃ³n](#-configuraciÃ³n)
- [Resultados y MÃ©tricas](#-resultados-y-mÃ©tricas)
- [API REST](#-api-rest)
- [MLflow Tracking](#-mlflow-tracking)
- [Versiones del Modelo](#-versiones-del-modelo)

---

## ğŸ¯ DescripciÃ³n

Este proyecto implementa un sistema de **credit scoring** utilizando un **PerceptrÃ³n Multicapa (MLP)** para predecir el riesgo crediticio de clientes bancarios. El modelo clasifica a los solicitantes de crÃ©dito en dos categorÃ­as:

- âœ… **Buen Riesgo** (Good Risk): Cliente con alta probabilidad de pago
- âŒ **Mal Riesgo** (Bad Risk): Cliente con riesgo de impago

### ğŸ”‘ CaracterÃ­sticas Principales

- **Deep Learning** con PyTorch
- **Preprocesamiento robusto** con sklearn pipelines
- **Arquitectura configurable** vÃ­a archivos YAML
- **Early stopping** y tÃ©cnicas de regularizaciÃ³n
- **Tracking de experimentos** con MLflow
- **API REST** para inferencia en producciÃ³n
- **Versionado de modelos** con DVC
- **ContainerizaciÃ³n** con Docker

---

## ğŸ—ï¸ Arquitectura del Proyecto

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  German Credit  â”‚
â”‚   Risk Dataset  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preprocessing   â”‚
â”‚ - StandardScalerâ”‚
â”‚ - OneHotEncoder â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MLP Model     â”‚
â”‚  [256-128-64-64]â”‚
â”‚  + Dropout      â”‚
â”‚  + BatchNorm    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Training      â”‚
â”‚ - BCEWithLogits â”‚
â”‚ - Adam Optimizerâ”‚
â”‚ - LR Scheduler  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Evaluation    â”‚
â”‚ - Accuracy: 78% â”‚
â”‚ - AUC: 0.82     â”‚
â”‚ - F1-Score: 0.75â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Deployment     â”‚
â”‚  FastAPI REST   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Dataset

### German Credit Risk Dataset

**UbicaciÃ³n**: `datasets/genia_services_csv_german_credit_risk_v1.0.0_training_20250825/`

**DescripciÃ³n**: Dataset histÃ³rico de clientes bancarios alemanes con informaciÃ³n demogrÃ¡fica, financiera y de historial crediticio.

#### Features del Dataset

| CategorÃ­a | Variables | Ejemplo |
|-----------|-----------|---------|
| **DemogrÃ¡ficas** | Age, Sex, Housing, Job | 35 aÃ±os, Male, Own |
| **Financieras** | Credit amount, Duration, Saving accounts | â‚¬5000, 24 meses, Little |
| **Historial** | Checking account, Purpose, Previous credits | Moderate, Car, 1 |
| **Target** | Risk | Good / Bad |

**DistribuciÃ³n**:
- Total de registros: 1000
- Buenos pagadores (Good): ~70%
- Malos pagadores (Bad): ~30%

#### Preprocesamiento

El pipeline de preprocesamiento (`CreditDataPreprocessor`) realiza:

1. **Variables NumÃ©ricas** â†’ `StandardScaler`
   ```python
   # NormalizaciÃ³n: x_scaled = (x - mean) / std
   ['Age', 'Credit amount', 'Duration']
   ```

2. **Variables CategÃ³ricas** â†’ `OneHotEncoder`
   ```python
   # Encoding binario
   ['Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose', 'Job']
   ```

3. **Output**: 26 features numÃ©ricas listas para la red neuronal

---

## ğŸ§  Modelo de Red Neuronal

### Arquitectura MLP (Multi-Layer Perceptron)

**Clase**: `CreditScoringModel` en `src/training/model.py`

#### ConfiguraciÃ³n del Modelo v1.3.0 (Mejor Rendimiento)

```
Input Layer (26 features)
    â†“
[Linear(26 â†’ 256) â†’ BatchNorm1d â†’ ReLU â†’ Dropout(0.1)]
    â†“
[Linear(256 â†’ 128) â†’ BatchNorm1d â†’ ReLU â†’ Dropout(0.1)]
    â†“
[Linear(128 â†’ 64) â†’ BatchNorm1d â†’ ReLU â†’ Dropout(0.1)]
    â†“
[Linear(64 â†’ 64) â†’ BatchNorm1d â†’ ReLU â†’ Dropout(0.1)]
    â†“
[Linear(64 â†’ 1)]  â† Output logits
    â†“
Sigmoid â†’ Probability [0, 1]
```

#### Componentes TÃ©cnicos

| Componente | FunciÃ³n | PropÃ³sito |
|------------|---------|-----------|
| **Linear** | `y = Wx + b` | TransformaciÃ³n lineal con pesos aprendibles |
| **BatchNorm1d** | NormalizaciÃ³n | Estabiliza entrenamiento, acelera convergencia |
| **ReLU** | `f(x) = max(0, x)` | ActivaciÃ³n no-lineal, previene vanishing gradient |
| **Dropout** | Apaga 10% neuronas | RegularizaciÃ³n, previene overfitting |
| **Sigmoid** | `Ïƒ(x) = 1/(1+e^-x)` | Convierte logits a probabilidades |

#### ParÃ¡metros del Modelo

```python
Total Parameters: ~58,000
Trainable Parameters: 100%
Model Size: ~230 KB
```

---

## ğŸ”„ Proceso de Entrenamiento

### Pipeline de Training

**Clase**: `CreditScoringModelTraining` en `src/training/train.py`

#### 1ï¸âƒ£ ConfiguraciÃ³n (YAML)

```yaml
training_params:
  epochs: 100
  batch_size: 32
  learning_rate: 0.001
  optimizer: "Adam"
  weight_decay: 0.0001
  
  early_stopping:
    patience: 10
    delta: 0.001
    
  lr_scheduler:
    type: "ReduceLROnPlateau"
    patience: 7
    factor: 0.5
```

#### 2ï¸âƒ£ Split de Datos

- **Training**: 80% (800 registros)
- **Validation**: 20% (200 registros)

#### 3ï¸âƒ£ FunciÃ³n de PÃ©rdida

**BCEWithLogitsLoss** (Binary Cross Entropy with Logits):

```python
Loss = -[y * log(Ïƒ(x)) + (1-y) * log(1-Ïƒ(x))]
```

- Combina Sigmoid + BCE en una operaciÃ³n numÃ©ricamente estable
- Penaliza predicciones incorrectas exponencialmente

#### 4ï¸âƒ£ Optimizador

**Adam** (Adaptive Moment Estimation):

```python
m_t = Î²â‚ * m_{t-1} + (1-Î²â‚) * âˆ‡L
v_t = Î²â‚‚ * v_{t-1} + (1-Î²â‚‚) * (âˆ‡L)Â²
Î¸_t = Î¸_{t-1} - Î± * m_t / (âˆšv_t + Îµ)
```

- Learning rate adaptativo por parÃ¡metro
- Momentum + RMSprop
- Î²â‚=0.9, Î²â‚‚=0.999

#### 5ï¸âƒ£ TÃ©cnicas de RegularizaciÃ³n

| TÃ©cnica | ConfiguraciÃ³n | Efecto |
|---------|--------------|--------|
| **Dropout** | 0.1 (10%) | Previene co-adaptaciÃ³n de neuronas |
| **L2 Regularization** | weight_decay=0.0001 | Penaliza pesos grandes |
| **Gradient Clipping** | max_norm=1.0 | Previene explosiÃ³n de gradientes |
| **Early Stopping** | patience=10 | Para entrenamiento si no mejora |
| **LR Scheduling** | ReduceLROnPlateau | Reduce LR cuando estanca |

#### 6ï¸âƒ£ Loop de Entrenamiento

```python
for epoch in range(100):
    # ğŸ”µ TRAINING PHASE
    model.train()
    for X_batch, y_batch in train_loader:
        # Forward pass
        logits = model(X_batch)
        loss = criterion(logits, y_batch)
        
        # Backward pass (RetropropagaciÃ³n)
        optimizer.zero_grad()
        loss.backward()  # Calcula âˆ‚Loss/âˆ‚W
        
        # Gradient clipping
        nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        
        # Update weights
        optimizer.step()  # W = W - lr * âˆ‚Loss/âˆ‚W
    
    # ğŸŸ¢ VALIDATION PHASE
    model.eval()
    with torch.no_grad():
        val_logits = model(X_val)
        val_loss = criterion(val_logits, y_val)
        val_probs = torch.sigmoid(val_logits)
        
        # Compute metrics
        accuracy = compute_accuracy(val_probs, y_val)
        auc = roc_auc_score(y_val, val_probs)
    
    # ğŸ“Š MLflow Logging
    mlflow.log_metrics({
        "train_loss": train_loss,
        "val_loss": val_loss,
        "val_accuracy": accuracy,
        "val_auc": auc
    }, step=epoch)
    
    # ğŸ›‘ Early Stopping Check
    if val_loss < best_val_loss - delta:
        best_val_loss = val_loss
        save_checkpoint(model, "best_model.pt")
        patience_counter = 0
    else:
        patience_counter += 1
        if patience_counter >= patience:
            print("Early stopping triggered!")
            break
    
    # ğŸ“‰ LR Scheduler
    scheduler.step(val_loss)
```

---

## ğŸ”§ InstalaciÃ³n

### Requisitos Previos

- Python 3.10 o superior
- pip o conda
- (Opcional) CUDA para entrenamiento con GPU

### InstalaciÃ³n con Virtual Environment

```bash
# Clonar repositorio
git clone https://github.com/montoyitadevelp/MLP--Multi-Layer-Perceptron-.git
cd MLP--Multi-Layer-Perceptron-/credit_scoring

# Crear entorno virtual
python3.10 -m venv venv310
source venv310/bin/activate  # En Windows: venv310\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### InstalaciÃ³n con Conda

```bash
# Crear entorno
conda create -n credit_scoring python=3.10
conda activate credit_scoring

# Instalar dependencias
pip install -r requirements.txt
```

### Dependencias Principales

```
torch>=2.0.0
scikit-learn>=1.3.0
pandas>=2.0.0
numpy>=1.24.0
mlflow>=2.7.0
fastapi>=0.100.0
uvicorn>=0.23.0
joblib>=1.3.0
pyyaml>=6.0
```

---

## ğŸš€ Uso

### 1. Entrenar un Nuevo Modelo

```bash
cd credit_scoring
python src/training/train.py \
  --config config/training/credit_scoring-training_config-german_credit_risk_v130.yaml
```

**Resultado**:
- Modelo guardado: `models/genia_services_mlp_credit_scoring_model_v1.3.0_[fecha].pt`
- Preprocessor: `models/german_credit_risk_preprocessor.joblib`
- Reportes: `reports/credit_scoring-training_config-german_credit_risk_v130_performance_report.yaml`

### 2. Evaluar Modelo Existente

```python
from src.training.train import CreditScoringModelTraining

trainer = CreditScoringModelTraining(
    config_path="config/training/credit_scoring-training_config-german_credit_risk_v130.yaml"
)
trainer.load_model("models/genia_services_mlp_credit_scoring_model_v1.3.0_20250824.pt")
metrics = trainer.evaluate()
print(metrics)
```

### 3. Inferencia (PredicciÃ³n Individual)

```python
from src.inference.predictor import CreditRiskPredictor

# Inicializar predictor
predictor = CreditRiskPredictor(
    model_path="models/genia_services_mlp_credit_scoring_model_v1.3.0_20250824.pt",
    preprocessor_path="models/german_credit_risk_preprocessor.joblib"
)

# Nueva solicitud de crÃ©dito
new_customer = {
    'Age': 30,
    'Sex': 'male',
    'Job': 2,
    'Housing': 'own',
    'Saving accounts': 'little',
    'Checking account': 'moderate',
    'Credit amount': 5000,
    'Duration': 24,
    'Purpose': 'car'
}

# Predecir
result = predictor.predict(new_customer)
print(f"Prediction: {result['prediction']}")  # 0 (Bad) o 1 (Good)
print(f"Probability: {result['probability']:.2%}")  # e.g., 78.50%
print(f"Risk Level: {result['risk_level']}")  # HIGH o LOW
```

### 4. Iniciar API REST

```bash
cd credit_scoring
uvicorn src.server.app:app --host 0.0.0.0 --port 8000 --reload
```

**Endpoint disponible**: `http://localhost:8000/predict`

**Ejemplo de Request**:

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "Age": 25,
    "Sex": "female",
    "Job": 2,
    "Housing": "rent",
    "Saving accounts": "little",
    "Checking account": "little",
    "Credit amount": 3000,
    "Duration": 12,
    "Purpose": "education"
  }'
```

**Response**:

```json
{
  "prediction": 1,
  "probability": 0.7845,
  "risk_level": "LOW",
  "model_version": "1.3.0",
  "timestamp": "2025-10-12T14:30:00Z"
}
```

### 5. Visualizar Tracking con MLflow

```bash
cd credit_scoring
mlflow ui --port 5000
```

Acceder a: `http://localhost:5000`

---

## ğŸ“ Estructura del Proyecto

```
credit_scoring/
â”‚
â”œâ”€â”€ ğŸ“‚ config/                      # Configuraciones
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ credit_scoring-training_config-german_credit_risk_v100.yaml
â”‚       â”œâ”€â”€ credit_scoring-training_config-german_credit_risk_v110.yaml
â”‚       â”œâ”€â”€ credit_scoring-training_config-german_credit_risk_v120.yaml
â”‚       â””â”€â”€ credit_scoring-training_config-german_credit_risk_v130.yaml
â”‚
â”œâ”€â”€ ğŸ“‚ datasets/                    # Datos
â”‚   â””â”€â”€ genia_services_csv_german_credit_risk_v1.0.0_training_20250825/
â”‚       â””â”€â”€ german_credit_risk.csv
â”‚
â”œâ”€â”€ ğŸ“‚ models/                      # Modelos entrenados
â”‚   â”œâ”€â”€ genia_services_mlp_credit_scoring_model_v1.0.0_20250824.pt
â”‚   â”œâ”€â”€ genia_services_mlp_credit_scoring_model_v1.1.0_20250824.pt
â”‚   â”œâ”€â”€ genia_services_mlp_credit_scoring_model_v1.2.0_20250824.pt
â”‚   â”œâ”€â”€ genia_services_mlp_credit_scoring_model_v1.3.0_20250824.pt
â”‚   â””â”€â”€ german_credit_risk_preprocessor.joblib
â”‚
â”œâ”€â”€ ğŸ“‚ reports/                     # Reportes de evaluaciÃ³n
â”‚   â”œâ”€â”€ classification_report_val.txt
â”‚   â”œâ”€â”€ credit_scoring-training_config-german_credit_risk_v100_performance_report.yaml
â”‚   â”œâ”€â”€ credit_scoring-training_config-german_credit_risk_v110_performance_report.yaml
â”‚   â”œâ”€â”€ credit_scoring-training_config-german_credit_risk_v120_performance_report.yaml
â”‚   â””â”€â”€ credit_scoring-training_config-german_credit_risk_v130_performance_report.yaml
â”‚
â”œâ”€â”€ ğŸ“‚ mlruns/                      # MLflow tracking
â”‚   â”œâ”€â”€ 0/                          # Default experiment
â”‚   â””â”€â”€ 393392644866618955/         # Credit Scoring experiment
â”‚       â”œâ”€â”€ 8b472c86.../            # Run IDs
â”‚       â”‚   â”œâ”€â”€ metrics/
â”‚       â”‚   â”œâ”€â”€ params/
â”‚       â”‚   â””â”€â”€ artifacts/
â”‚       â””â”€â”€ models/
â”‚
â”œâ”€â”€ ğŸ“‚ src/                         # CÃ³digo fuente
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ processing/              # Preprocesamiento
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ main.py                 # CreditDataPreprocessor
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ training/                # Entrenamiento
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model.py                # CreditScoringModel (arquitectura)
â”‚   â”‚   â””â”€â”€ train.py                # CreditScoringModelTraining (training loop)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ inference/               # Inferencia
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ predictor.py            # CreditRiskPredictor
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ server/                  # API REST
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ app.py                  # FastAPI app
â”‚   â”‚   â””â”€â”€ schemas.py              # Pydantic models
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ examples/                # Scripts de ejemplo
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                       # Tests unitarios
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_model_creation.py
â”‚
â”œâ”€â”€ ğŸ“‚ venv311/                     # Virtual environment
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt             # Dependencias de producciÃ³n
â”œâ”€â”€ ğŸ“„ requirements_training.txt    # Dependencias de entrenamiento
â”œâ”€â”€ ğŸ“„ Dockerfile                   # Container image
â”œâ”€â”€ ğŸ“„ .dockerignore
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ models.dvc                   # DVC tracking de modelos
â””â”€â”€ ğŸ“„ reports.dvc                  # DVC tracking de reportes
```

---

## âš™ï¸ ConfiguraciÃ³n

### Archivo de ConfiguraciÃ³n (YAML)

**Ejemplo**: `config/training/credit_scoring-training_config-german_credit_risk_v130.yaml`

```yaml
# Metadata del modelo
model_info:
  name: "credit_scoring"
  version: "1.3.0"
  description: "MLP for German Credit Risk prediction"
  date: "2025-08-24"

# ConfiguraciÃ³n del dataset
data:
  path: "datasets/genia_services_csv_german_credit_risk_v1.0.0_training_20250825/german_credit_risk.csv"
  target_column: "Risk"
  test_size: 0.2
  random_state: 42
  stratify: true

# Arquitectura del modelo
model_architecture:
  input_features: 26
  hidden_layers: [256, 128, 64, 64]
  output_size: 1
  activation: "relu"
  dropout_rate: 0.1
  use_batch_norm: true

# ParÃ¡metros de entrenamiento
training_params:
  epochs: 100
  batch_size: 32
  learning_rate: 0.001
  optimizer: "Adam"
  weight_decay: 0.0001
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 10
    delta: 0.001
    monitor: "val_loss"
  
  # Learning rate scheduler
  lr_scheduler:
    type: "ReduceLROnPlateau"
    mode: "min"
    factor: 0.5
    patience: 7
    min_lr: 0.00001
  
  # Gradient clipping
  gradient_clipping:
    enabled: true
    max_norm: 1.0

# ConfiguraciÃ³n de MLflow
mlflow:
  experiment_name: "credit_scoring_german_credit_risk"
  tracking_uri: "mlruns"
  artifact_location: "mlruns/artifacts"

# Rutas de salida
output:
  model_path: "models/"
  preprocessor_path: "models/"
  reports_path: "reports/"
```

### Variables de Entorno

```bash
# .env
MLFLOW_TRACKING_URI=mlruns
MODEL_VERSION=1.3.0
API_PORT=8000
DEVICE=cuda  # o 'cpu'
```

---

## ğŸ“ˆ Resultados y MÃ©tricas

### ComparaciÃ³n de Versiones

| VersiÃ³n | Arquitectura | Dropout | Val Accuracy | Val AUC | Val F1 | Epochs |
|---------|--------------|---------|--------------|---------|--------|--------|
| v1.0.0 | [128, 64] | 0.1 | 75.2% | 0.79 | 0.72 | 82 |
| v1.1.0 | [128, 64, 64] | 0.1 | 76.8% | 0.80 | 0.73 | 91 |
| v1.2.0 | [128, 64, 64] | 0.2 | 77.5% | 0.81 | 0.74 | 95 |
| **v1.3.0** | **[256, 128, 64, 64]** | **0.1** | **78.3%** | **0.82** | **0.75** | **88** |

### Mejor Modelo: v1.3.0

#### MÃ©tricas de ValidaciÃ³n

```
Accuracy:  78.3%
Precision: 79.1%
Recall:    76.8%
F1-Score:  0.75
AUC-ROC:   0.82
```

#### Confusion Matrix (Validation Set)

```
                 Predicted
                Bad    Good
Actual  Bad      85      15
        Good     28     122
```

#### Curvas de Aprendizaje

**Training vs Validation Loss**:
- Convergencia estable en epoch 88
- Sin evidencia de overfitting significativo
- Early stopping activado correctamente

**ROC Curve**:
- AUC = 0.82
- Buen balance entre TPR y FPR

#### Importancia Relativa de Features

Top 5 features mÃ¡s influyentes:
1. `Checking account`
2. `Credit amount`
3. `Duration`
4. `Saving accounts`
5. `Age`

---

## ğŸŒ API REST

### Endpoints

#### 1. Health Check

```
GET /health
```

**Response**:
```json
{
  "status": "healthy",
  "model_version": "1.3.0",
  "uptime": "2h 15m"
}
```

#### 2. PredicciÃ³n

```
POST /predict
```

**Request Body**:
```json
{
  "Age": 30,
  "Sex": "male",
  "Job": 2,
  "Housing": "own",
  "Saving accounts": "little",
  "Checking account": "moderate",
  "Credit amount": 5000,
  "Duration": 24,
  "Purpose": "car"
}
```

**Response**:
```json
{
  "prediction": 1,
  "probability": 0.7845,
  "risk_level": "LOW",
  "confidence": "HIGH",
  "model_version": "1.3.0",
  "timestamp": "2025-10-12T14:30:00Z",
  "processing_time_ms": 12.5
}
```

#### 3. PredicciÃ³n en Batch

```
POST /predict/batch
```

**Request Body**:
```json
{
  "customers": [
    { "Age": 30, "Sex": "male", ... },
    { "Age": 25, "Sex": "female", ... },
    { "Age": 40, "Sex": "male", ... }
  ]
}
```

**Response**:
```json
{
  "predictions": [
    { "id": 0, "prediction": 1, "probability": 0.7845 },
    { "id": 1, "prediction": 0, "probability": 0.3521 },
    { "id": 2, "prediction": 1, "probability": 0.8912 }
  ],
  "total_processed": 3,
  "processing_time_ms": 35.2
}
```

#### 4. InformaciÃ³n del Modelo

```
GET /model/info
```

**Response**:
```json
{
  "name": "Credit Scoring MLP",
  "version": "1.3.0",
  "architecture": {
    "input_features": 26,
    "hidden_layers": [256, 128, 64, 64],
    "output_size": 1,
    "total_parameters": 58241
  },
  "training_date": "2025-08-24",
  "metrics": {
    "accuracy": 0.783,
    "auc": 0.82,
    "f1_score": 0.75
  }
}
```

### DocumentaciÃ³n Interactiva

Una vez iniciado el servidor, accede a:

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

---

## ğŸ“Š MLflow Tracking

### Iniciar MLflow UI

```bash
cd credit_scoring
mlflow ui --port 5000
```

Acceder a: `http://localhost:5000`

### InformaciÃ³n Registrada

#### ParÃ¡metros (Params)

```python
{
    'learning_rate': 0.001,
    'batch_size': 32,
    'epochs': 100,
    'hidden_layers': '[256, 128, 64, 64]',
    'dropout_rate': 0.1,
    'optimizer': 'Adam',
    'weight_decay': 0.0001
}
```

#### MÃ©tricas (Metrics)

```python
# Por epoch
{
    'train_loss': [0.65, 0.52, 0.45, ...],
    'val_loss': [0.68, 0.55, 0.48, ...],
    'val_accuracy': [0.68, 0.72, 0.75, ...],
    'val_auc': [0.72, 0.76, 0.80, ...],
    'val_f1': [0.65, 0.70, 0.73, ...],
    'learning_rate': [0.001, 0.001, 0.0005, ...]
}
```

#### Artifacts

```
artifacts/
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ model.pt
â”‚   â””â”€â”€ preprocessor.joblib
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â”œâ”€â”€ precision_recall_curve.png
â”‚   â””â”€â”€ learning_curves.png
â””â”€â”€ reports/
    â”œâ”€â”€ classification_report.txt
    â””â”€â”€ performance_summary.yaml
```

### Comparar Experimentos

```python
import mlflow

# Buscar runs
runs = mlflow.search_runs(
    experiment_names=["credit_scoring_german_credit_risk"],
    order_by=["metrics.val_auc DESC"]
)

print(runs[['run_id', 'params.hidden_layers', 'metrics.val_auc']])
```

---

## ğŸ”„ Versiones del Modelo

### Versionado con DVC

```bash
# Track modelos
dvc add models/genia_services_mlp_credit_scoring_model_v1.3.0_20250824.pt

# Track reportes
dvc add reports/credit_scoring-training_config-german_credit_risk_v130_performance_report.yaml

# Commit
git add models.dvc reports.dvc
git commit -m "Track model v1.3.0"

# Push a remote storage
dvc push
```

### Historial de Versiones

| Fecha | VersiÃ³n | Cambios | Performance |
|-------|---------|---------|-------------|
| 2025-08-20 | v1.0.0 | Baseline: [128, 64] | AUC: 0.79 |
| 2025-08-21 | v1.1.0 | +1 hidden layer | AUC: 0.80 |
| 2025-08-22 | v1.2.0 | Dropout: 0.1â†’0.2 | AUC: 0.81 |
| 2025-08-24 | v1.3.0 | Arquitectura mÃ¡s profunda | AUC: 0.82 âœ… |

---

## ğŸ³ Docker

### Construir Imagen

```bash
cd credit_scoring
docker build -t credit-scoring-mlp:v1.3.0 .
```

### Ejecutar Container

```bash
docker run -d \
  --name credit-scoring-api \
  -p 8000:8000 \
  -v $(pwd)/models:/app/models \
  credit-scoring-mlp:v1.3.0
```

### Docker Compose

```yaml
# docker-compose.yml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
    environment:
      - MODEL_VERSION=1.3.0
      - DEVICE=cpu
    restart: unless-stopped
```

```bash
docker-compose up -d
```

---

## ğŸ§ª Testing

### Ejecutar Tests

```bash
cd credit_scoring
pytest tests/ -v
```

### Tests Implementados

```python
# tests/test_model_creation.py
def test_model_creation():
    """Verifica creaciÃ³n correcta del modelo"""
    
def test_forward_pass():
    """Verifica forward pass con input dummy"""
    
def test_preprocessor():
    """Verifica transformaciones del preprocessor"""
    
def test_prediction_pipeline():
    """Test end-to-end de predicciÃ³n"""
```

---

## ğŸ“š Conceptos TÃ©cnicos

### RetropropagaciÃ³n (Backpropagation)

El algoritmo de retropropagaciÃ³n calcula gradientes de la funciÃ³n de pÃ©rdida respecto a todos los pesos:

```
âˆ‚Loss/âˆ‚W = âˆ‚Loss/âˆ‚output Ã— âˆ‚output/âˆ‚hidden Ã— âˆ‚hidden/âˆ‚W
```

PyTorch lo hace automÃ¡ticamente con `loss.backward()`.

### Adam Optimizer

Combina momentum y RMSprop:

```python
# Momento de primer orden (momentum)
m_t = Î²â‚ * m_{t-1} + (1-Î²â‚) * âˆ‡L

# Momento de segundo orden (RMSprop)
v_t = Î²â‚‚ * v_{t-1} + (1-Î²â‚‚) * (âˆ‡L)Â²

# ActualizaciÃ³n con correcciÃ³n de sesgo
Î¸_t = Î¸_{t-1} - Î± * mÌ‚_t / (âˆšvÌ‚_t + Îµ)
```

### Batch Normalization

Normaliza activaciones por mini-batch:

```python
Î¼_B = (1/m) * Î£x_i          # Media del batch
ÏƒÂ²_B = (1/m) * Î£(x_i - Î¼_B)Â²  # Varianza del batch
xÌ‚_i = (x_i - Î¼_B) / âˆš(ÏƒÂ²_B + Îµ)  # NormalizaciÃ³n
y_i = Î³ * xÌ‚_i + Î²           # Escala y desplazamiento aprendibles
```

### Early Stopping

Para entrenamiento cuando la mÃ©trica de validaciÃ³n no mejora:

```python
if val_loss < best_val_loss - delta:
    best_val_loss = val_loss
    patience_counter = 0
    save_checkpoint()
else:
    patience_counter += 1
    if patience_counter >= patience:
        stop_training()
```

---

## ğŸ› ï¸ Troubleshooting

### Error: CUDA out of memory

**SoluciÃ³n**:
```python
# Reducir batch size
batch_size: 16  # en lugar de 32

# O entrenar en CPU
device: 'cpu'
```

### Error: Model performance degradation

**Posibles causas**:
1. Overfitting â†’ Aumentar dropout
2. Underfitting â†’ Aumentar hidden layers
3. Learning rate muy alto â†’ Reducir lr
4. Data drift â†’ Re-entrenar con datos nuevos

### Error: API request timeout

**SoluciÃ³n**:
```python
# En app.py
@app.post("/predict", timeout=30.0)

# O aumentar gunicorn timeout
gunicorn src.server.app:app --timeout 60
```

---

## ğŸ“– Referencias

### Papers

- **Multi-Layer Perceptron**: Rumelhart et al. (1986)
- **Adam Optimizer**: Kingma & Ba (2014)
- **Batch Normalization**: Ioffe & Szegedy (2015)
- **Dropout**: Srivastava et al. (2014)

### DocumentaciÃ³n

- [PyTorch Documentation](https://pytorch.org/docs/)
- [scikit-learn User Guide](https://scikit-learn.org/stable/)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)

### Dataset

- **German Credit Risk**: UCI Machine Learning Repository

---

## ğŸ‘¥ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -m 'Add nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

---

## ğŸ“§ Contacto

**Proyecto**: [MLP Credit Scoring](https://github.com/montoyitadevelp/MLP--Multi-Layer-Perceptron-)

**Autor**: montoyitadevelp

---

## â­ Agradecimientos

- Dataset: UCI Machine Learning Repository
- Framework: PyTorch Team
- Tracking: MLflow Community
- API: FastAPI Team

---

**Â¡Gracias por usar MLP Credit Scoring!** ğŸ‰
